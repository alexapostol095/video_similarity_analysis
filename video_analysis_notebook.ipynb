{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5dadec",
   "metadata": {},
   "source": [
    "# SIAMESE NETWORK EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94af4c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T13:40:08.022949Z",
     "start_time": "2024-01-24T13:40:07.965611Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob #Directory library\n",
    "import logging \n",
    "import os\n",
    "import cv2 #Computer vision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm import tqdm #Progress bar library\n",
    "\n",
    "#Configuration\n",
    "CONFIG = {\n",
    "    \"frame_dimensions\": (720, 1280),\n",
    "    \"fps\": 1,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"video_extension\": \"mp4\",\n",
    "    \"policy1_dir\": \"./policy1\",\n",
    "    \"policy2_dir\": \"./policy2\",\n",
    "    \"training_video_name\": \"Bud_Light_15s_Folds_of_Honor_First_Responders_Fund.mp4\", #Video selected for training\n",
    "}\n",
    "\n",
    "# Logging for development\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Siamese Network architecture\n",
    "def siamese_network(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', name='dense_siamese'),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Data Preparation\n",
    "def gather_video_files(directory, extension=\"mp4\"):\n",
    "    files = glob.glob(f\"{directory}/*.{extension}\")\n",
    "    return files\n",
    "\n",
    "# Frame Extraction\n",
    "def extract_frames(video_file, target_size, fps):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = round(frame_rate / fps)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for frame_id in range(0, frame_count, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, target_size, interpolation=cv2.INTER_AREA)\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Extract Features\n",
    "def extract_siamese_features(model, frames):\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "        feature = model.predict(frame)\n",
    "        features.append(feature.flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# Save Embeddings to CSV\n",
    "def embeddings_to_csv(video_file, features, csv_filename):\n",
    "    df = pd.DataFrame(features, columns=[f\"feature_{i}\" for i in range(features.shape[1])])\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6541b75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T13:48:08.328546Z",
     "start_time": "2024-01-24T13:40:30.455157Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gathering video files for both policies.\n",
      "INFO:root:Loading Siamese network model.\n",
      "INFO:root:Extracting frames and features from the training video for pre-training.\n",
      "Training Video Frames: 100%|█████████████████| 15/15 [00:00<00:00, 49971.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 48s 48s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 27s 27s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 22s 22s/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Gather video files for Policy 1 and Policy 2\n",
    "logging.info(\"Gathering video files for both policies.\")\n",
    "policy1_files = gather_video_files(CONFIG[\"policy1_dir\"], CONFIG[\"video_extension\"])\n",
    "policy2_files = gather_video_files(CONFIG[\"policy2_dir\"], CONFIG[\"video_extension\"])\n",
    "\n",
    "# Check if video files are found\n",
    "if not policy1_files:\n",
    "    logging.error(\"No video files found for Policy 1. Check the directory and file extension.\")\n",
    "\n",
    "\n",
    "if not policy2_files:\n",
    "    logging.error(\"No video files found for Policy 2. Check the directory and file extension.\")\n",
    "\n",
    "\n",
    "# Load the Siamese network model\n",
    "logging.info(\"Loading Siamese network model.\")\n",
    "siamese_model = siamese_network((1280, 720, 3))\n",
    "\n",
    "# Extract frames and features from the training video for pre-training\n",
    "logging.info(\"Extracting frames and features from the training video for pre-training.\")\n",
    "training_video = os.path.join(CONFIG[\"policy1_dir\"], CONFIG[\"training_video_name\"])\n",
    "training_frames = [\n",
    "    frame\n",
    "    for frame in tqdm(extract_frames(training_video, CONFIG[\"frame_dimensions\"], CONFIG[\"fps\"]), desc=\"Training Video Frames\")\n",
    "]\n",
    "training_features = extract_siamese_features(siamese_model, training_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5da59081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T14:17:48.461116Z",
     "start_time": "2024-01-24T13:48:25.769382Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting frames and features from Policy 1 videos.\n",
      "Policy 1 Videos:   0%|                                    | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 54s 54s/step\n",
      "1/1 [==============================] - 31s 31s/step\n",
      "1/1 [==============================] - 27s 27s/step\n",
      "1/1 [==============================] - 27s 27s/step\n",
      "1/1 [==============================] - 35s 35s/step\n",
      "1/1 [==============================] - 27s 27s/step\n",
      "1/1 [==============================] - 32s 32s/step\n",
      "1/1 [==============================] - 28s 28s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Policy 1 Videos:  50%|█████████████▌             | 1/2 [04:26<04:26, 266.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 26s 26s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 25s 25s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 26s 26s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Policy 1 Videos: 100%|███████████████████████████| 2/2 [10:10<00:00, 305.08s/it]\n",
      "INFO:root:Extracting frames and features from Policy 2 videos.\n",
      "Policy 2 Videos: 100%|████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 27s 27s/step\n",
      "1/1 [==============================] - 29s 29s/step\n",
      "1/1 [==============================] - 26s 26s/step\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 28s 28s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 25s 25s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 28s 28s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 24s 24s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 29s 29s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 20s 20s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 23s 23s/step\n",
      "1/1 [==============================] - 21s 21s/step\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 19s 19s/step\n"
     ]
    }
   ],
   "source": [
    "# Set the weights of the Siamese network based on features learned from the training video\n",
    "dense_siamese_weights = siamese_model.get_layer('dense_siamese').get_weights()\n",
    "siamese_model.layers[-1].set_weights(dense_siamese_weights)\n",
    "\n",
    "# Extract frames and features from each Policy 1 video and save to separate CSV files\n",
    "logging.info(\"Extracting frames and features from Policy 1 videos.\")\n",
    "for policy1_file in tqdm(policy1_files, desc=\"Policy 1 Videos\"):\n",
    "    policy1_frames = [\n",
    "        frame\n",
    "        for frame in extract_frames(policy1_file, CONFIG[\"frame_dimensions\"], CONFIG[\"fps\"])]\n",
    "    policy1_features = extract_siamese_features(siamese_model, policy1_frames)\n",
    "    policy1_filename = os.path.basename(policy1_file)\n",
    "    embeddings_to_csv([policy1_filename], policy1_features, f\"policy1_{policy1_filename}_embeddings.csv\")\n",
    "\n",
    "# Extract frames and features from Policy 2 videos and save to CSV\n",
    "logging.info(\"Extracting frames and features from Policy 2 videos.\")\n",
    "policy2_frames = [frame for file in tqdm(policy2_files, desc=\"Policy 2 Videos\") for frame in extract_frames(file, CONFIG[\"frame_dimensions\"], CONFIG[\"fps\"])]\n",
    "policy2_features = extract_siamese_features(siamese_model, policy2_frames)\n",
    "embeddings_to_csv(policy2_files, policy2_features, \"policy2_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad093dc",
   "metadata": {},
   "source": [
    "# SimCLR EMBEDDINGS (No training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce6e63e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T14:24:37.155577Z",
     "start_time": "2024-01-24T14:24:37.133449Z"
    }
   },
   "outputs": [],
   "source": [
    "# SimCLR data augmentation\n",
    "def get_simclr_augmentation(input_shape=(224, 224, 3)):\n",
    "    data_augmentation = models.Sequential([\n",
    "        preprocessing.Rescaling(1./255),\n",
    "        preprocessing.RandomFlip(\"horizontal\"),\n",
    "        preprocessing.RandomRotation(0.5),\n",
    "        preprocessing.RandomZoom(0.5),\n",
    "        preprocessing.RandomContrast(0.5),\n",
    "    ], name=\"simclr_augmentation\")\n",
    "\n",
    "    input_a = layers.Input(shape=input_shape)\n",
    "    augmented_a = data_augmentation(input_a)\n",
    "\n",
    "    return input_a, augmented_a\n",
    "\n",
    "# SimCLR encoder\n",
    "def get_simclr_encoder(base_encoder, projection_dim=128):\n",
    "    inputs = layers.Input(shape=(None, None, 3))\n",
    "    x = base_encoder(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(projection_dim, activation='relu')(x)\n",
    "    encoder = models.Model(inputs, x)\n",
    "    return encoder\n",
    "\n",
    "# SimCLR model\n",
    "def get_simclr_model(encoder, temperature=0.1):\n",
    "    input_a, augmented_a = get_simclr_augmentation()\n",
    "\n",
    "    # Encode augmented images\n",
    "    encoded_a = encoder(augmented_a)\n",
    "\n",
    "    # Create SimCLR model\n",
    "    simclr_model = models.Model(inputs=input_a, outputs=encoded_a)\n",
    "\n",
    "    return simclr_model\n",
    "\n",
    "\n",
    "def extract_simclr_features(model, frames):\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        # Resize frame to match the expected input shape of (224, 224)\n",
    "        frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "        feature = model.predict(frame)\n",
    "        features.append(feature.flatten())\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "798f7d73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T14:24:54.467751Z",
     "start_time": "2024-01-24T14:24:38.370230Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gathering video files for both policies.\n",
      "Policy 1 Videos:   0%|                                    | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Policy 1 Videos:  50%|██████████████              | 1/2 [00:01<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Policy 1 Videos: 100%|████████████████████████████| 2/2 [00:02<00:00,  1.45s/it]\n",
      "Policy 2 Videos:   0%|                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Policy 2 Videos: 100%|████████████████████████████| 1/1 [00:05<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Gather video files for Policy 1 and Policy 2\n",
    "logging.info(\"Gathering video files for both policies.\")\n",
    "policy1_files = glob.glob(f\"{CONFIG['policy1_dir']}/*.{CONFIG['video_extension']}\")\n",
    "policy2_files = glob.glob(f\"{CONFIG['policy2_dir']}/*.{CONFIG['video_extension']}\")\n",
    "\n",
    "base_encoder = tf.keras.applications.ResNet50(input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "simclr_encoder = get_simclr_encoder(base_encoder)\n",
    "\n",
    "simclr_model = get_simclr_model(simclr_encoder)\n",
    "\n",
    "for policy1_file in tqdm(policy1_files, desc=\"Policy 1 Videos\"):\n",
    "    policy1_frames = [cv2.resize(frame, CONFIG[\"frame_dimensions\"], interpolation=cv2.INTER_AREA) for frame in extract_frames(policy1_file, CONFIG[\"frame_dimensions\"], CONFIG[\"fps\"])]\n",
    "    policy1_features = extract_simclr_features(simclr_model, policy1_frames)\n",
    "    embeddings_to_csv([os.path.basename(policy1_file)], policy1_features, f\"policy1_{os.path.basename(policy1_file)}_simclr_embeddings.csv\")\n",
    "\n",
    "# Use the encoder for inference and save embeddings to CSV for Policy 2\n",
    "for policy2_file in tqdm(policy2_files, desc=\"Policy 2 Videos\"):\n",
    "    policy2_frames = [cv2.resize(frame, CONFIG[\"frame_dimensions\"], interpolation=cv2.INTER_AREA) for frame in extract_frames(policy2_file, CONFIG[\"frame_dimensions\"], CONFIG[\"fps\"])]\n",
    "    policy2_features = extract_simclr_features(simclr_model, policy2_frames)\n",
    "    embeddings_to_csv([os.path.basename(policy2_file)], policy2_features, f\"policy2_{os.path.basename(policy2_file)}_simclr_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a25bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
